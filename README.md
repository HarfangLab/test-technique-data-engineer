# Data Engineer / Technical Case

üëã Welcome! Here's everything you need to work on the Data Engineer technical case which is part of HarfangLab's recruitement process.

‚ÑπÔ∏è Instead of doing this technical case, you can share some relevant code you're proud of that you have done on a previous project

## Overview

### About the interview

The technical case is primarily a discussion support for the onsite technical interview. The topics are intentionally dense, especially considering that the preparation period may be very short. The goal isn't to cover everything exhaustively but to provide an overall understanding and let you develop the areas of work you wish. We will ask you at the beginning of the interview how much time you were able to dedicate to this preparation.

We want to see code. It's important that this code can be executed. This allows us to observe your habits and understand your thought process. As 
mentioned above, you can provide us with code you've done elsewhere.  

### The Data Platform

This repository contains all of the code that makes up the Data Platform. The Data Platform is in charge of processing the data at HarfangLab for the AI and CTI (Cyber Threat Intelligence) teams.

The cornerstone of the Data Platform is the Datawarehouse: it is an analytical database containing detailed information on files. These files are stored separetely (you won't need them).

üí° Although this repository only exists within the context of the technical test, the internal architecture we have is very similar to the one described here (with more complex and detailed information on the files).

### The Data Model

AI and CTI teams' needs are quite straightforward. Many files are scrapped every day and they need easy access to their information.

#### Sample

A file is materialized by a `Sample` in the Datawarehouse. It contains information about the filename, mime, magic and sha256 of the file. This is the central piece of the Datawarehouse.

#### Analysis and Analyzer

Frequently, some files are selected and analyzed automatically by reliable automatic analyzer solutions (`AUTO_A`, `AUTO_B`, `AUTO_C`, `AUTO_D`, `AUTO_E` and `AUTO_F`). These analyses are pushed into the table `Analysis`.


#### Tag and TagType

`Tags` contain precise information on specific samples. A tag can contain information about the malware family of the sample or whether the sample was detected in production environment. The type of the tag is specified in a split table `TagType`.


#### Malware Family

Malware families have many aliases. A mapping between the conventional naming of the family and its known aliases is given in the table `MalwareFamily`.

## Technical Details

### Components

The Data Platform relies on the following technologies:

The Datawarehouse is a PostgreSQL database. It is ran inside of a container using `docker compose`.

‚ö†Ô∏è Obviously, in the context of the technical test, we do not extract data from any application. Instead, the data is randomly generated by `faker` on launch of the container.

## Usage

To be able to run the project, you will need Docker and Docker Compose.

To build the Docker image containing the Data Platform and launch all the steps to populate the Datawarehouse, simply run the `docker compose up` command.

You can modify the amount of rows you want to populate the Data Platform with using the `NB_ROWS` environment variable. To generate 10,000 rows simply run `NB_ROWS=10000 docker compose up`. You should see in the logs `database system is ready to accept connections` and `Data generation ended successfully` to indicate that everything is up and running properly. For large data amounts, the generation will take time. You can monitor an ongoing generation with `docker attach --sig-proxy=false <populate-container-id>`.

üí• The `docker compose up` command alone should work without any errors... If you encounter any issues, please contact us: this should not happen!

üí° Be sure that all the modifications you're making allow to start off from this `docker compose up` as we will run the tests using an existing database generated with it!

‚ùì Is everything clear? If so, find the exercises to complete [here](./exercises/summary.md)!

## Cleanup

You can simply stop the database and remove the generated data by runnning the usual `docker compose down -v` command.
